# micrograd

A step-by-step implementation of [Andrej Karpathy's micrograd](https://github.com/karpathy/micrograd) - a tiny scalar-valued autograd engine and neural network library.

## Description

This repository contains a learning implementation of micrograd, a minimal autograd engine that implements backpropagation (reverse-mode autodiff) over a dynamically built DAG. The implementation includes:

- **Autograd Engine**: A tiny scalar-valued autograd engine that builds computation graphs dynamically
- **Neural Network Library**: A small neural networks library on top of the engine with a PyTorch-like API
- **Educational Purpose**: Built step-by-step to understand the fundamentals of automatic differentiation and neural networks

## Original Repository

This is a learning implementation based on the original micrograd by Andrej Karpathy:
- Original: https://github.com/karpathy/micrograd
- License: MIT
